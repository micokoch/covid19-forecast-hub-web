---
title: Weekly reports
layout: docs
---

We follow a weekly update cycle at the COVID-19 Forecast Hub. Every Tuesday morning, our team assembles the most recent forecasts from all teams that have submitted in the last week. We use these data to generate an <a href="https://covid19forecasthub.org/doc/ensemble/">ensemble forecast</a> that synthesizes predictions of COVID-19 hospitalizations from all eligible models. These forecasts are then reviewed, analyzed, and verified by our collaborators at the US CDC. On Thursday mornings, the CDC updates their <a href="https://www.cdc.gov/coronavirus/2019-ncov/science/forecasting/mathematical-modeling.html" target="_blank">COVID-19 Forecasting webpage</a> with the latest data from the COVID-19 Forecast Hub.  
Update: As of February 20, 2023, we are no longer generating ensemble case forecasts, and as of March 6, 2023, we are no longer generating ensemble death forecasts. Reports up to March 13, 2023 include case and death forecast evaluations, but after that date they only include hospitalization forecast evaluations.  

## <a href="https://covid19forecasthub.org/reports/single_page.html">Forecast Summaries</a>
Each week, we also generate a weekly report that provides some top-level summary numbers from the ensemble forecast. <a href="https://covid19forecasthub.org/reports/single_page.html">Browse current and past forecast summaries</a>.

## <a href="https://covid19forecasthub.org/eval-reports">Forecast Evaluations</a>
Periodically, we evaluate the accuracy and precision of the <a href="https://covid19forecasthub.org/doc/ensemble/">ensemble forecast</a> and component models over recent and historical forecasting periods. Models forecasting incident hospitalizations at a national and state level are evaluated using (<a href="https://arxiv.org/abs/2005.12881" target="_blank">adjusted relative weighted interval scores (WIS, a measure of distributional accuracy)</a>, and adjusted relative mean absolute error (MAE), and calibration scores. Scores are evaluated across weeks, locations, and targets. You can read <a href="https://www.medrxiv.org/content/10.1101/2021.02.03.21250974v1" target="_blank">a paper explaining these procedures in more detail</a>, and look at <a href="https://covid19forecasthub.org/eval-reports">the most recent monthly evaluation reports</a>. The final report that includes case and death forecast evaluations is 2023-03-13.  

## <a href="https://delphi.cmu.edu/forecast-eval/">Forecast Evaluation Dashboard</a>
In collaboration with the COVID-19 Forecast Hub, the Delphi Group at Carnegie Mellon University has created a <a href="https://delphi.cmu.edu/forecast-eval/">Forecast Evaluation Dashboard</a> that compares the performance of models over time, using different outcome variables (incident cases and deaths), metrics (Weighted Interval Score, Absolute Error, and Coverage), horizons (1 through 4 week forecasts), and locations (US national and state levels). As of February 20, 2023, case forecasts are no longer being updated and as of March 6, 2023 death forecasts are no longer being updated. Learn more <a href="https://delphi.cmu.edu/forecast-eval/">about the dashboard</a> and <a href="https://github.com/cmu-delphi/forecast-eval/">download the code on GitHub</a>.  

***
